name: Scheduled Crawler

on:
  schedule:
    - cron: "50 3 * * *" # 每天UTC 4點 (台北12點)
  workflow_dispatch:
  
jobs:
  crawler:
    runs-on: ubuntu-latest

    steps:
      - name: Install Docker Compose
        run: |
          sudo apt-get update
          sudo apt-get install -y docker-compose
          
      # Step 1: 檢出程式碼
      - name: Checkout code
        uses: actions/checkout@v3

      # Step 2: 設定 Docker Compose
      - name: Set up Docker Compose
        run: |
          docker volume create --name=mysql
          docker network create my_network
          docker-compose -f mysql.yml up -d

      - name: List running Docker containers
        run: docker ps
        
      - name: Import SQL
        run: |
          docker exec -i linpoi387_mysql_1 mysql -u root -ptest -h 127.0.0.1 crawler < crawler.sql

      # Step 5: Display phpMyAdmin URL
      - name: Output phpMyAdmin URL
        run: echo "phpMyAdmin is available at http://localhost:8080"
        
      # Step 4: 執行爬蟲
      - name: api_scheduler.py
        run: |
          pip install apscheduler
          pip install loguru
          pip install requests
          pip install beautifulsoup4
          pip install mysql.connector
          pip install fastapi
          pip install uvicorn
          pip install sqlalchemy
          pip install pandas
          python api_scheduler.py

      # Step 5: 停止 Docker Compose
      - name: Stop Docker Compose
        run: |
          docker-compose mysql.yml down
