name: Scheduled Crawler

on:
  schedule:
    - cron: "50 3 * * *" # 每天UTC 4點 (台北12點)
  workflow_dispatch:
  
jobs:
  crawler:
    runs-on: ubuntu-latest

    steps:
      - name: Install Docker Compose
        run: |
          sudo apt-get update
          sudo apt-get install -y docker-compose
          
      # Step 1: 檢出程式碼
      - name: Checkout code
        uses: actions/checkout@v3

      # Step 2: 設定 Docker Compose
      - name: Set up Docker Compose
        run: |
          docker volume create --name=mysql
          docker network create my_network
          docker-compose -f mysql.yml up -d

      - name: List running Docker containers
        run: |
          docker ps
          docker network ls

      - name: 等待 MySQL 啟動
        run: |
          for i in {1..10}; do
            docker exec linpoi387_mysql_1 mysqladmin ping -h "127.0.0.1" -u root -ptest && break
            echo "等待 MySQL 啟動..."
            sleep 3
          done
          
      - name: 共享crawler.sql
        run: |
          docker run --name mysql-container \
          -e MYSQL_ROOT_PASSWORD=test \
          -e MYSQL_DATABASE=crawler \
          -e MYSQL_USER=root \
          -e MYSQL_PASSWORD=test \
          -d mysql:latest
     
      - name: Import SQL
        run: |
          docker exec -i linpoi387_mysql_1 mysql -u root -ptest crawler < crawler.sql

      # Step 5: Display phpMyAdmin URL
      - name: Output phpMyAdmin URL
        run: echo "phpMyAdmin is available at http://localhost:8080"
        
      # Step 4: 執行爬蟲
      - name: api_scheduler.py
        run: |
          pip install apscheduler
          pip install loguru
          pip install requests
          pip install beautifulsoup4
          pip install mysql.connector
          pip install fastapi
          pip install uvicorn
          pip install sqlalchemy
          pip install pandas
          python api_scheduler.py

      # Step 5: 停止 Docker Compose
      - name: Stop Docker Compose
        run: |
          docker-compose mysql.yml down
